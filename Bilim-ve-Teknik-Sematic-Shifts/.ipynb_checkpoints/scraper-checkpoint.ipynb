{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for scraping\n",
    "from tqdm import tqdm as tqdm\n",
    "import pandas as pd\n",
    "import bs4 as bs\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BTScraper:\n",
    "    def __init__(self, page_from, page_to):\n",
    "        self.page_from = page_from\n",
    "        self.page_to = page_to\n",
    "        \n",
    "        self.base_url = 'https://bilimteknik.tubitak.gov.tr/arsiv/yillara-gore-arama?field_yil_ay_value%5Bvalue%5D%5Byear%5D=&page='\n",
    "        self.page_urls = [self.base_url + str(i) for i in range(self.page_from, self.page_to)]\n",
    "        self.issue_urls = []\n",
    "        self.pdf_urls = []\n",
    "        \n",
    "        self.existing_files = []\n",
    "        self.downloaded_files = []\n",
    "        \n",
    "        self.page_errors = []\n",
    "        self.issue_errors = []\n",
    "        self.download_errors = []\n",
    "        \n",
    "    ## Visits each page with number between page_from - page_to\n",
    "    ## Finds issue urls in html eg. https://bilimteknik.tubitak.gov.tr/pdf/kasim-1968\n",
    "    def get_issue_url(self):\n",
    "        \n",
    "        print('Extracting issue urls')\n",
    "        time.sleep(1)\n",
    "        \n",
    "        for url in tqdm(self.page_urls):\n",
    "            try:\n",
    "                response = requests.get(url)\n",
    "                soup = bs.BeautifulSoup(response.content, 'html.parser')\n",
    "                divs = soup.find_all('div', class_='span4')\n",
    "            \n",
    "                adress_list = [div.a['href'] for div in divs if div.a != None]\n",
    "            \n",
    "                # Getting the links related with only pdf files\n",
    "                match_list = [re.match(r'/pdf/', ref).string for ref in adress_list if re.match(r'/pdf/', ref) != None]\n",
    "                issue_urls_temp = ['https://bilimteknik.tubitak.gov.tr' + match for match in match_list]\n",
    "                \n",
    "                self.issue_urls.extend(issue_urls_temp)\n",
    "            except:\n",
    "                self.page_errors.append(url)\n",
    "                continue\n",
    "            \n",
    "            if len(self.page_errors) > 0:\n",
    "                for error in self.page_errors:\n",
    "                    self.page_urls.remove(error)\n",
    "            \n",
    "            time.sleep(0.01)\n",
    "    \n",
    "    ## Finds pdf urls in \n",
    "    def get_pdf_url(self):\n",
    "        print('Extracting pdf urls')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        for issue in tqdm(self.issue_urls):\n",
    "            try:\n",
    "                response = requests.get(issue)\n",
    "                soup = bs.BeautifulSoup(response.content, 'html.parser')\n",
    "                main = soup.find(id='block-system-main')\n",
    "                content = main.find_all('span', class_='field-content')\n",
    "                \n",
    "                self.pdf_urls.append(content[0].a.a['href'])\n",
    "            except:\n",
    "                self.issue_errors.append(issue)\n",
    "                continue\n",
    "        \n",
    "        if len(self.issue_errors) > 0:    \n",
    "            for error in self.issue_errors:\n",
    "                self.issue_urls.remove(error)\n",
    "            \n",
    "            time.sleep(0.01)\n",
    "    \n",
    "    ## Creates a pandas DataFrame from url, year, month and filename data\n",
    "    def create_data(self):\n",
    "        for url in self.issue_urls:\n",
    "            year_list = [re.findall('\\d{4}', url)[0] for url in self.issue_urls]\n",
    "            month_list = [re.findall('ocak|subat|mart|nisan|mayis|haziran|temmuz|agustos|eylul|ekim|kasim|aralik', url)[0] for url in self.issue_urls]\n",
    "            path_list = ['pdf_files/' + year + '/' for year in year_list]\n",
    "            filename_list = [month + '-' + year + '.pdf' for month, year in zip(month_list, year_list)]\n",
    "\n",
    "        # Creating a DataFrame to keep it organized\n",
    "        data_dict = {'year':year_list, 'month':month_list, 'path':path_list, 'filename':filename_list, 'url':self.pdf_urls}\n",
    "        data = pd.DataFrame(data_dict)\n",
    "        data.to_csv('url-data.txt', index=False) # Saving\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    ## Downloads the pdfs and organizes them by year\n",
    "    def download_pdf(self, data):\n",
    "        print('Downloading')\n",
    "        # pd.DataFrame.iterrows() does not work with tqdm\n",
    "        # working around it\n",
    "        row_list = []\n",
    "        for row in data.iterrows():\n",
    "            row_list.append(row)\n",
    "            \n",
    "        time.sleep(1)\n",
    "        \n",
    "        for row in tqdm(row_list):\n",
    "        \n",
    "            # Finding file and folder names from urls\n",
    "            # to be organized\n",
    "            filename = row[1][3]\n",
    "            year = row[1][0]\n",
    "            save_path = row[1][2]\n",
    "            url = row[1][4]\n",
    "            \n",
    "            # Creating filepaths to save the pdfs\n",
    "            if not os.path.exists(os.path.dirname(save_path)):\n",
    "                os.makedirs(os.path.dirname(save_path))\n",
    "        \n",
    "            save_file = save_path + filename\n",
    "          \n",
    "            if (os.path.isfile(save_file)):\n",
    "                # Do nothing if file exists\n",
    "                self.existing_files.append(filename)\n",
    "            else:\n",
    "                # Download if the file does not exist\n",
    "                try:\n",
    "                    response = requests.get(url.strip())\n",
    "                    self.downloaded_files.append(filename)\n",
    "                except:\n",
    "                    self.download_errors.append(url)\n",
    "                    continue\n",
    "                    \n",
    "                with open(save_file, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "            time.sleep(0.01)\n",
    "        \n",
    "        print(f'{len(self.existing_files)} files already exist.')\n",
    "        print(f'{len(self.downloaded_files)} files downloaded.')\n",
    "        print(f'{len(self.download_errors) + len(self.issue_errors) + len(self.page_errors)} errors occured while downloading.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting issue urls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:56<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting pdf urls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [11:18<00:00,  2.62s/it]\n"
     ]
    }
   ],
   "source": [
    "# the issues from year 1999 starts at page 31\n",
    "# select 31-53 to download only the files currently used in the project (1999-2020)\n",
    "\n",
    "s = BTScraper(31, 53) # select the page interval you want to download, 0-53 for all pdf files (1967-2020)\n",
    "s.get_issue_url()\n",
    "s.get_pdf_url()\n",
    "data = s.create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>path</th>\n",
       "      <th>filename</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>kasim</td>\n",
       "      <td>pdf_files/1998/</td>\n",
       "      <td>kasim-1998.pdf</td>\n",
       "      <td>https://bilimteknik.tubitak.gov.tr/system/file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1998</td>\n",
       "      <td>aralik</td>\n",
       "      <td>pdf_files/1998/</td>\n",
       "      <td>aralik-1998.pdf</td>\n",
       "      <td>https://bilimteknik.tubitak.gov.tr/system/file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1999</td>\n",
       "      <td>ocak</td>\n",
       "      <td>pdf_files/1999/</td>\n",
       "      <td>ocak-1999.pdf</td>\n",
       "      <td>https://bilimteknik.tubitak.gov.tr/system/file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1999</td>\n",
       "      <td>subat</td>\n",
       "      <td>pdf_files/1999/</td>\n",
       "      <td>subat-1999.pdf</td>\n",
       "      <td>https://bilimteknik.tubitak.gov.tr/system/file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1999</td>\n",
       "      <td>mart</td>\n",
       "      <td>pdf_files/1999/</td>\n",
       "      <td>mart-1999.pdf</td>\n",
       "      <td>https://bilimteknik.tubitak.gov.tr/system/file...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   month             path         filename  \\\n",
       "0  1998   kasim  pdf_files/1998/   kasim-1998.pdf   \n",
       "1  1998  aralik  pdf_files/1998/  aralik-1998.pdf   \n",
       "2  1999    ocak  pdf_files/1999/    ocak-1999.pdf   \n",
       "3  1999   subat  pdf_files/1999/   subat-1999.pdf   \n",
       "4  1999    mart  pdf_files/1999/    mart-1999.pdf   \n",
       "\n",
       "                                                 url  \n",
       "0  https://bilimteknik.tubitak.gov.tr/system/file...  \n",
       "1  https://bilimteknik.tubitak.gov.tr/system/file...  \n",
       "2  https://bilimteknik.tubitak.gov.tr/system/file...  \n",
       "3  https://bilimteknik.tubitak.gov.tr/system/file...  \n",
       "4  https://bilimteknik.tubitak.gov.tr/system/file...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('url-data.txt')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>path</th>\n",
       "      <th>filename</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>2020</td>\n",
       "      <td>ocak</td>\n",
       "      <td>pdf_files/2020/</td>\n",
       "      <td>ocak-2020.pdf</td>\n",
       "      <td>https://bilimteknik.tubitak.gov.tr/system/file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>2020</td>\n",
       "      <td>subat</td>\n",
       "      <td>pdf_files/2020/</td>\n",
       "      <td>subat-2020.pdf</td>\n",
       "      <td>https://bilimteknik.tubitak.gov.tr/system/file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>2020</td>\n",
       "      <td>mart</td>\n",
       "      <td>pdf_files/2020/</td>\n",
       "      <td>mart-2020.pdf</td>\n",
       "      <td>https://bilimteknik.tubitak.gov.tr/system/file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>2020</td>\n",
       "      <td>nisan</td>\n",
       "      <td>pdf_files/2020/</td>\n",
       "      <td>nisan-2020.pdf</td>\n",
       "      <td>https://bilimteknik.tubitak.gov.tr/system/file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>2020</td>\n",
       "      <td>mayis</td>\n",
       "      <td>pdf_files/2020/</td>\n",
       "      <td>mayis-2020.pdf</td>\n",
       "      <td>https://bilimteknik.tubitak.gov.tr/system/file...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month             path        filename  \\\n",
       "254  2020   ocak  pdf_files/2020/   ocak-2020.pdf   \n",
       "255  2020  subat  pdf_files/2020/  subat-2020.pdf   \n",
       "256  2020   mart  pdf_files/2020/   mart-2020.pdf   \n",
       "257  2020  nisan  pdf_files/2020/  nisan-2020.pdf   \n",
       "258  2020  mayis  pdf_files/2020/  mayis-2020.pdf   \n",
       "\n",
       "                                                   url  \n",
       "254  https://bilimteknik.tubitak.gov.tr/system/file...  \n",
       "255  https://bilimteknik.tubitak.gov.tr/system/file...  \n",
       "256  https://bilimteknik.tubitak.gov.tr/system/file...  \n",
       "257  https://bilimteknik.tubitak.gov.tr/system/file...  \n",
       "258  https://bilimteknik.tubitak.gov.tr/system/file...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [00:02<00:00, 92.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259 files already exist.\n",
      "0 files downloaded.\n",
      "0 errors occured while downloading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = BTScraper(31, 53)\n",
    "s.download_pdf(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
